{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"CLAUDE_API_KEY\")\n",
    "MODEL_NAME = os.getenv(\"CLAUDE_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Athropic client configuration\n",
    "client = anthropic.Anthropic(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading file\n",
    "def loading_document(path):\n",
    "  \n",
    "    with open(path, 'r', encoding='utf-8') as archivo:\n",
    "        return archivo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing document on chunks\n",
    "def dividing_document(text, chunk_size=1000, chunk_overlap=200):\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation embeddings for chunnks\n",
    "def creation_embeddings(chunks):\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "    vectorstore = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovering the most important chunks for the consult\n",
    "def recovering_context(vectorstore, query, top_k=3):\n",
    "    \n",
    "    return vectorstore.similarity_search(query, k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an aswer usig Claude with the recovered context\n",
    "def generate_answer_with_context(query, context):\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in context])\n",
    "    \n",
    "    system_prompt = \"\"\"Eres un asistente experto en análisis de documentos técnicos.\n",
    "    Utiliza el contexto proporcionado para responder de manera precisa y detallada.\n",
    "    Si la información no está en el contexto, indica que no puedes responder.\"\"\"\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Contexto: {context_text}\\n\\nPregunta: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflection process for improving the answer\n",
    "def reflection_process(pregunta, initial_answer):\n",
    "\n",
    "    system_prompt = \"Eres un analista técnico crítico que evalúa soluciones de manera objetiva.\"\n",
    "    \n",
    "    # Evaluation\n",
    "    evaluation = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        system=system_prompt,\n",
    "        max_tokens=2000,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Evalúa críticamente esta respuesta:\\n{initial_answer}\\n\\nCriterios de evaluación:\\n- Precisión\\n- Completitud\\n- Claridad\\n- Relevancia\"}\n",
    "        ]\n",
    "    ).content[0].text\n",
    "    \n",
    "    # Auto-reflection\n",
    "    autoreflection = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        system=system_prompt,\n",
    "        max_tokens=2000,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Basándote en la respuesta y evaluación:\\n\\nRespuesta: {initial_answer}\\n\\nEvaluación: {evaluation}\\n\\nGenera una reflexión con estrategias de mejora.\"}\n",
    "        ]\n",
    "    ).content[0].text\n",
    "    \n",
    "    # Better answer\n",
    "    better_answer = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        system=system_prompt,\n",
    "        max_tokens=2000,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Partiendo de:\\nPregunta Original: {pregunta}\\nRespuesta Inicial: {initial_answer}\\nEvaluación: {evaluation}\\nReflexión: {autoreflection}\\n\\nGenera una versión MEJORADA de la respuesta.\"}\n",
    "        ]\n",
    "    ).content[0].text\n",
    "    \n",
    "    return {\n",
    "        'respuesta_inicial': initial_answer,\n",
    "        'evaluacion': evaluation,\n",
    "        'autoreflexion': autoreflection,\n",
    "        'respuesta_mejorada': better_answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultig Documentation\n",
    "def consulting_doc(query):\n",
    "   \n",
    "    # Loading and processing document\n",
    "    document = loading_document(\"./info.txt\")\n",
    "    chunks = dividing_document(document)\n",
    "    vectorstore = creation_embeddings(chunks)\n",
    "    \n",
    "    # Recovering important context\n",
    "    context = recovering_context(vectorstore, query)\n",
    "    \n",
    "    # Generation of the initial answer with RAG\n",
    "    initial_answer = generate_answer_with_context(query, context)\n",
    "    \n",
    "    # Reflection process\n",
    "    resultado_reflexion = reflection_process(query, initial_answer)\n",
    "    \n",
    "    return resultado_reflexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Respuesta Inicial ###\n",
      "De acuerdo con el contexto proporcionado, los principales objetivos del proyecto Nebula son:\n",
      "\n",
      "1. Proporcionar un sistema SaaS accesible y eficiente para la creación y evaluación de modelos de aprendizaje automático, específicamente para tareas de regresión y clasificación.\n",
      "\n",
      "2. Diseñar una plataforma que brinde una experiencia intuitiva y automatizada, permitiendo a usuarios con diversos niveles de experiencia en ciencia de datos crear modelos precisos sin necesidad de conocimientos avanzados en machine learning.\n",
      "\n",
      "3. Lograr que la arquitectura de Nebula sea escalable y modular, facilitando la integración de nuevas funcionalidades y mejoras a medida que evolucionen las necesidades de los usuarios.\n",
      "\n",
      "En resumen, los objetivos principales son proporcionar una plataforma SaaS accesible y eficiente para el desarrollo de modelos de aprendizaje automático, con una arquitectura escalable y modular que permita adaptarse a las necesidades cambiantes de los usuarios.\n",
      "\n",
      "### Evaluación ###\n",
      "Aquí está mi evaluación crítica de la respuesta proporcionada:\n",
      "\n",
      "Precisión:\n",
      "La descripción de los objetivos del proyecto Nebula parece ser precisa y coherente con la información proporcionada. No se observan inexactitudes o afirmaciones erróneas.\n",
      "\n",
      "Completitud:\n",
      "La respuesta cubre los principales objetivos del proyecto, incluyendo proporcionar un sistema SaaS accesible y eficiente, diseñar una plataforma intuitiva y automatizada, y lograr que la arquitectura sea escalable y modular. Estos objetivos parecen abarcar los aspectos clave del proyecto.\n",
      "\n",
      "Claridad:\n",
      "La redacción de la respuesta es clara y fácil de entender. Los objetivos se presentan de manera estructurada y se explican con detalle suficiente.\n",
      "\n",
      "Relevancia:\n",
      "Los objetivos descritos son altamente relevantes para el contexto proporcionado, ya que se enfocan en facilitar el desarrollo de modelos de aprendizaje automático de manera accesible y adaptable a las necesidades cambiantes de los usuarios.\n",
      "\n",
      "En general, la respuesta es sólida y cumple con los criterios de evaluación. Proporciona una descripción precisa, completa, clara y relevante de los principales objetivos del proyecto Nebula. No se observan deficiencias significativas en la respuesta.\n",
      "\n",
      "### Auto-Reflexión ###\n",
      "Después de analizar detalladamente la respuesta proporcionada, considero que es una evaluación sólida y objetiva de los objetivos del proyecto Nebula. Algunos aspectos a tener en cuenta para posibles estrategias de mejora:\n",
      "\n",
      "1. Énfasis en la accesibilidad:\n",
      "   - Resaltar aún más el enfoque en hacer que la plataforma sea accesible para usuarios con diversos niveles de experiencia en ciencia de datos. Esto podría incluir detalles sobre las funciones y herramientas diseñadas específicamente para facilitar el uso de la plataforma.\n",
      "\n",
      "2. Detalles sobre la automatización:\n",
      "   - Profundizar un poco más en cómo la plataforma proporciona una experiencia automatizada para la creación y evaluación de modelos de aprendizaje automático. Proporcionar ejemplos o características específicas que permiten este nivel de automatización.\n",
      "\n",
      "3. Escalabilidad y modularidad:\n",
      "   - Ampliar la explicación sobre cómo se logra la escalabilidad y modularidad en la arquitectura de Nebula. Mencionar posibles beneficios o ventajas concretas de estas características, como la facilidad de integración de nuevas funcionalidades o la capacidad de adaptarse a diversos volúmenes de datos y usuarios.\n",
      "\n",
      "4. Alineación con tendencias y necesidades del mercado:\n",
      "   - Sería útil incluir algunas observaciones sobre cómo los objetivos de Nebula se alinean con las tendencias y necesidades actuales en el campo del aprendizaje automático y la ciencia de datos. Esto podría resaltar la relevancia y relevancia del proyecto.\n",
      "\n",
      "5. Impacto potencial:\n",
      "   - Agregar una breve sección que describa el impacto o beneficios potenciales que el proyecto Nebula puede tener, tanto para los usuarios finales como para el avance de la ciencia de datos en general.\n",
      "\n",
      "Estas son algunas sugerencias que podrían fortalecer aún más la evaluación y hacer que la respuesta sea aún más informativa y convincente. En general, la respuesta original es sólida y proporciona una evaluación objetiva y detallada de los objetivos del proyecto Nebula.\n",
      "\n",
      "### Respuesta Mejorada ###\n",
      "Aquí está una versión mejorada de la respuesta:\n",
      "\n",
      "Los principales objetivos del proyecto Nebula son:\n",
      "\n",
      "1. Proporcionar una plataforma SaaS accesible y eficiente para la creación y evaluación de modelos de aprendizaje automático, especialmente para tareas de regresión y clasificación.\n",
      "\n",
      "   - La plataforma está diseñada para ser intuitiva y automatizada, permitiendo a usuarios con diversos niveles de experiencia en ciencia de datos desarrollar modelos de machine learning precisos sin necesidad de conocimientos avanzados.\n",
      "   - Esto se logra mediante funciones y herramientas específicas que simplifican el proceso de construcción y validación de modelos, haciéndolo más accesible para profesionales no técnicos.\n",
      "\n",
      "2. Diseñar una arquitectura escalable y modular que facilite la integración de nuevas funcionalidades y mejoras.\n",
      "\n",
      "   - La escalabilidad de Nebula permite adaptarse a las cambiantes necesidades de los usuarios, abarcando desde pequeños proyectos hasta implementaciones a gran escala.\n",
      "   - La modularidad de la plataforma posibilita la incorporación de avances tecnológicos y la adición de nuevas características sin interrumpir el servicio.\n",
      "\n",
      "3. Alinear los objetivos de Nebula con las tendencias y necesidades actuales del mercado en el campo del aprendizaje automático y la ciencia de datos.\n",
      "\n",
      "   - El proyecto Nebula responde a la creciente demanda de herramientas accesibles y eficientes para el desarrollo de modelos de machine learning, especialmente en sectores como finanzas, salud y comercio electrónico.\n",
      "   - Al simplificar el proceso de creación de modelos, Nebula busca democratizar el acceso a la inteligencia artificial, permitiendo que más profesionales puedan aprovechar sus beneficios.\n",
      "\n",
      "En resumen, Nebula tiene como objetivo principal brindar una plataforma SaaS escalable, modular y accesible para el desarrollo de modelos de aprendizaje automático, con el fin de impulsar la adopción de la IA en diversos sectores y facilitar la toma de decisiones basadas en datos.\n"
     ]
    }
   ],
   "source": [
    "# Use examples\n",
    "query = \"¿Cuáles son los objetivos principales del proyecto Nebula?\"\n",
    "result = consulting_doc(query)\n",
    "\n",
    "print(\"### Respuesta Inicial ###\")\n",
    "print(result['respuesta_inicial'])\n",
    "print(\"\\n### Evaluación ###\")\n",
    "print(result['evaluacion'])\n",
    "print(\"\\n### Auto-Reflexión ###\")\n",
    "print(result['autoreflexion'])\n",
    "print(\"\\n### Respuesta Mejorada ###\")\n",
    "print(result['respuesta_mejorada'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
